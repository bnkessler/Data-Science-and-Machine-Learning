{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxbDFsJARAMD"
   },
   "source": [
    "# Palmer Penguins Modeling\n",
    "\n",
    "Import the Palmer Penguins dataset and print out the first few rows.\n",
    "\n",
    "Suppose we want to predict `species` using the other variables in the dataset.\n",
    "\n",
    "**Dummify** all variables that require this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "QV2uolyOQ65C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code Here\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from palmerpenguins import load_penguins\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, label_binarize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, f1_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# penguins['Adelie'] = (penguins['species'] == 'Adelie').astype(int)\n",
    "# penguins['Gentoo'] = (penguins['species'] == 'Gentoo').astype(int)\n",
    "# penguins['Chinstrap'] = (penguins['species'] == 'Chinstrap').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "4       3450.0  female  2007  \n",
       "5       3650.0    male  2007  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins = load_penguins()\n",
    "penguins = penguins.dropna()\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = penguins.drop([\"species\"], axis = 1)\n",
    "y = penguins[\"species\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HecNBVAnRHod"
   },
   "source": [
    "Let's use the other variables to predict `species`. Prepare your data and fit the following models on the entire dataset:\n",
    "\n",
    "* Two kNN models (for different values of K)\n",
    "* Two decision tree models (for different complexities of trees)\n",
    "\n",
    "Compute the following, for each of your models, on test data. Keep in mind that you may need to stratify your creation of the training and test data.\n",
    "\n",
    "* Confusion matrix\n",
    "* Overall Accuracy\n",
    "* Precision, Recall, AUC, and F1-score for each species\n",
    "\n",
    "Create one ROC plot for the species of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "U1onRGJQR8T_"
   },
   "outputs": [],
   "source": [
    "# kNN Model 1 \n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", \n",
    "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
    "    make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", \n",
    "    StandardScaler(), \n",
    "    make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "knn_pipeline_1 = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", ct),\n",
    "        (\"knn\", KNeighborsClassifier(n_neighbors=5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "fitted_pipeline = knn_pipeline_1.fit(X_train, y_train)\n",
    "y_pred = fitted_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[35  0  1]\n",
      " [ 0 33  0]\n",
      " [ 1  0 14]] \n",
      "Overall Accuracy: 0.9761904761904762 \n",
      "Precision: [0.97222222 0.93333333 1.        ] \n",
      "Recall: [0.97222222 0.93333333 1.        ] \n",
      "AUC: 0.9992275563607086 \n",
      "F1 Score: [0.97222222 0.93333333 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cmatrix = confusion_matrix(y_true = y_test, y_pred=y_pred, labels = [\"Adelie\", \"Gentoo\", \"Chinstrap\"])\n",
    "\n",
    "# Overall Accuracy\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average = None)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_true = y_test, y_pred = y_pred, average = None)\n",
    "\n",
    "# AUC (need to fix)\n",
    "auc = roc_auc_score(y_score = fitted_pipeline.predict_proba(X_test), y_true = y_test, multi_class = \"ovr\", average=\"macro\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_pred = y_pred, y_true = y_test, average = None)\n",
    "print(f\"Confusion Matrix:\\n {cmatrix} \\nOverall Accuracy: {accuracy} \\nPrecision: {precision} \\nRecall: {recall} \\nAUC: {auc} \\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kNN Model 2\n",
    "knn_pipeline_2 = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", ct),\n",
    "        (\"knn\", KNeighborsClassifier(n_neighbors=25))\n",
    "    ]\n",
    ")\n",
    "\n",
    "fitted_pipeline = knn_pipeline_2.fit(X_train, y_train)\n",
    "y_pred = fitted_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[28  0  0]\n",
      " [ 0 38  0]\n",
      " [ 1  0 17]] \n",
      "Overall Accuracy: 0.9880952380952381 \n",
      "Precision: [0.96551724 1.         1.        ] \n",
      "Recall: [1.         0.94444444 1.        ] \n",
      "AUC: 0.9995068313520695 \n",
      "F1 Score: [0.98245614 0.97142857 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cmatrix = confusion_matrix(y_true = y_test, y_pred=y_pred, labels = [\"Adelie\", \"Gentoo\", \"Chinstrap\"])\n",
    "\n",
    "# Overall Accuracy\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average = None)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_true = y_test, y_pred = y_pred, average = None)\n",
    "\n",
    "# AUC (need to fix)\n",
    "auc = roc_auc_score(y_score = fitted_pipeline.predict_proba(X_test), y_true = y_test, multi_class=\"ovr\", average=\"macro\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_pred = y_pred, y_true = y_test, average = None)\n",
    "print(f\"Confusion Matrix:\\n {cmatrix} \\nOverall Accuracy: {accuracy} \\nPrecision: {precision} \\nRecall: {recall} \\nAUC: {auc} \\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decision Tree 1\n",
    "dtree_pipeline_1 = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", ct),\n",
    "        (\"dtree\", DecisionTreeClassifier(ccp_alpha=.1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "fitted_pipeline = dtree_pipeline_1.fit(X_train, y_train)\n",
    "y_pred = fitted_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[25  0  3]\n",
      " [ 2 36  0]\n",
      " [ 1  0 17]] \n",
      "Overall Accuracy: 0.9285714285714286 \n",
      "Precision: [0.89285714 0.85       1.        ] \n",
      "Recall: [0.89285714 0.94444444 0.94736842] \n",
      "AUC: 0.9629008134238601 \n",
      "F1 Score: [0.89285714 0.89473684 0.97297297]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cmatrix = confusion_matrix(y_true = y_test, y_pred=y_pred, labels = [\"Adelie\", \"Gentoo\", \"Chinstrap\"])\n",
    "\n",
    "# Overall Accuracy\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average = None)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_true = y_test, y_pred = y_pred, average = None)\n",
    "\n",
    "# AUC (need to fix)\n",
    "auc = roc_auc_score(y_score = fitted_pipeline.predict_proba(X_test), y_true = y_test, multi_class=\"ovr\", average=\"macro\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_pred = y_pred, y_true = y_test, average = None)\n",
    "print(f\"Confusion Matrix:\\n {cmatrix} \\nOverall Accuracy: {accuracy} \\nPrecision: {precision} \\nRecall: {recall} \\nAUC: {auc} \\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decision Tree 2\n",
    "dtree_pipeline_2 = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", ct),\n",
    "        (\"dtree\", DecisionTreeClassifier(ccp_alpha=1e-5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "fitted_pipeline = dtree_pipeline_2.fit(X_train, y_train)\n",
    "y_pred = fitted_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[28  0  0]\n",
      " [ 1 37  0]\n",
      " [ 1  0 17]] \n",
      "Overall Accuracy: 0.9761904761904762 \n",
      "Precision: [0.93333333 1.         1.        ] \n",
      "Recall: [1.         0.94444444 0.97368421] \n",
      "AUC: 0.9804023948760792 \n",
      "F1 Score: [0.96551724 0.97142857 0.98666667]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cmatrix = confusion_matrix(y_true = y_test, y_pred=y_pred, labels = [\"Adelie\", \"Gentoo\", \"Chinstrap\"])\n",
    "\n",
    "# Overall Accuracy\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, average = None)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_true = y_test, y_pred = y_pred, average = None)\n",
    "\n",
    "# AUC (need to fix)\n",
    "auc = roc_auc_score(y_score = fitted_pipeline.predict_proba(X_test), y_true = y_test, multi_class=\"ovr\", average=\"macro\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_pred = y_pred, y_true = y_test, average = None)\n",
    "print(f\"Confusion Matrix:\\n {cmatrix} \\nOverall Accuracy: {accuracy} \\nPrecision: {precision} \\nRecall: {recall} \\nAUC: {auc} \\nF1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
